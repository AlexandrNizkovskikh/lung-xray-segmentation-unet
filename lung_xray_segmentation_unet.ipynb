{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Введение"
      ],
      "metadata": {
        "id": "srDCGkscrMc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация проекта сегментации радиографических снимков легких человека.\n",
        "\n",
        "Проект посвящён аугментации изображений здоровых лёгких для увеличения объёма данных и повышения точности моделей сегментации."
      ],
      "metadata": {
        "id": "FCCpGyBhroMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_kGd8XCMNFyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек"
      ],
      "metadata": {
        "id": "L0in_MznNBxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qwTRWYRMxIx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf                                                               # библиотека Tensorflow\n",
        "import keras                                                                          # библиотека Keras\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU, Rescaling     # cлои библиотеки Keras\n",
        "from keras.layers import BatchNormalization, Conv2DTranspose, Concatenate             # cлои библиотеки Keras\n",
        "from keras.layers import Rescaling, Resizing                                          # cлои библиотеки Keras\n",
        "from keras.models import Model, Sequential                                            # конструкторы построения моделей библиотеки Keras\n",
        "\n",
        "from keras.optimizers import Adam                                                     # оптимизатор Adam\n",
        "from keras.preprocessing.image import  load_img, img_to_array                         # загрузка изображений\n",
        "from keras.utils import to_categorical                                                # преобразует вектор класса (целые числа) в двоичную матрицу класса\n",
        "\n",
        "\n",
        "\n",
        "import random                                                                         # генератор случайных чисел\n",
        "\n",
        "import numpy as np                                                                    # библиотека линейной алгебры\n",
        "import pandas as pd                                                                   # библиотека обработки табличных данных\n",
        "import os                                                                             # библиотека работы с функциями операционной системы, в том числе с файлами\n",
        "import albumentations as A                                                            # библиотека аугментации изображений (https://albumentations.ai/)\n",
        "\n",
        "import matplotlib.pyplot as plt                                                       # библиотека для рисования графиков\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и подготовка датасета"
      ],
      "metadata": {
        "id": "s8n746pfNLye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as op\n",
        "op.download(\"https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/\")"
      ],
      "metadata": {
        "id": "-GSTKEVjbwMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal'\n",
        "\n",
        "image_dir = 'images'\n",
        "label_dir = 'masks'"
      ],
      "metadata": {
        "id": "d6esgrwnNLMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функция для отображения"
      ],
      "metadata": {
        "id": "O0HYi2QFNRru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Входное изображение', 'Оригинальная маска', 'Предсказанная ма.ска']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.utils.array_to_img(display_list[0]))\n",
        "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]),alpha=0.5)                # маска с прозрачностью 50%\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "MWURdZAlNOaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = os.path.join(dataset_path, image_dir, 'Normal-1.png')                        # путь до ориганального изображения\n",
        "masks = os.path.join(dataset_path, label_dir, 'Normal-1.png')                         # путь до маски\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "img = np.array(load_img(images, target_size=(256, 256), color_mode='rgb'))\n",
        "mask = np.array(load_img(masks, target_size=(256, 256), color_mode='grayscale'))\n",
        "\n",
        "axs[0].imshow(img)                                                                    # оригинальное изображение\n",
        "axs[0].grid(False)\n",
        "\n",
        "axs[1].imshow(mask)                                                                   # маска\n",
        "axs[1].grid(False)"
      ],
      "metadata": {
        "id": "aPsVw_OxNVV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Константы"
      ],
      "metadata": {
        "id": "zGe3VoO0Nj6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (256, 256)\n",
        "NUM_CLASSES = 2\n",
        "batch_size = 16\n",
        "seed = 1523\n",
        "val_samples = 1000\n",
        "img_size = IMG_SIZE\n",
        "num_classes = NUM_CLASSES\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "XhdcoTQHNksf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сортировка"
      ],
      "metadata": {
        "id": "LNQH8K7NWtIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_path = sorted(\n",
        "    [\n",
        "        os.path.join(dataset_path, image_dir, fname)\n",
        "        for fname in os.listdir(os.path.join(dataset_path, image_dir))\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_img_path = sorted(\n",
        "    [\n",
        "        os.path.join(dataset_path, label_dir, fname)\n",
        "        for fname in os.listdir(os.path.join(dataset_path, label_dir))\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "xiQ9S1xHNlz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация данных"
      ],
      "metadata": {
        "id": "f57ozVMhW191"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class datasetGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, batch_size,\n",
        "                 img_size,\n",
        "                 input_img_path,\n",
        "                 target_img_path = None,\n",
        "                 num_classes = NUM_CLASSES,\n",
        "                 validation = False,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)                                                    # вызов конструктора базового класса\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_path = input_img_path\n",
        "        self.target_img_path = target_img_path\n",
        "        self.num_classes = num_classes\n",
        "        self.validation = validation\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Возвращает число мини-батчей обучающей выборки\"\"\"\n",
        "        return len(self.target_img_path) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Возвращает кортеж (input, target) соответствующий индексу пакета idx\"\"\"\n",
        "\n",
        "        batch_input_img_path = self.input_img_path[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_target_img_path = self.target_img_path[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "\n",
        "        x = np.zeros((self.batch_size, *self.img_size, 3), dtype=\"float32\")\n",
        "        y = np.zeros((self.batch_size, *self.img_size, self.num_classes), dtype=\"uint8\")\n",
        "\n",
        "        for _, paths in enumerate(zip(batch_input_img_path, batch_target_img_path)):\n",
        "            img = np.array(load_img(paths[0], target_size=self.img_size, color_mode='rgb'))\n",
        "            mask = np.array(load_img(paths[1], target_size=self.img_size, color_mode='grayscale'))\n",
        "\n",
        "            if self.validation == False:\n",
        "                # Применяем аугментацию для проверочной выборки (p - вероятность применения, 0.5 - для каждого второго изображения)\n",
        "                transform = A.Compose([                                               # функция аугментации\n",
        "                              A.Flip(p=0.5),                                          # Отражение изображения по горизонтали и вертикали\n",
        "                                A.RandomRotate90(always_apply=False, p=0.5)           # Случайный поворот на 90 градусов\n",
        "                                 ])\n",
        "                transformed = transform(image=img, mask=mask)                         # примение функции аугментации к изображению и маске\n",
        "                img = transformed[\"image\"]\n",
        "                mask = transformed[\"mask\"]\n",
        "\n",
        "            x[_] = img / 255.0                                                        # нормализация изображения\n",
        "            mask[mask > self.num_classes - 1] = self.num_classes - 1                  # исправление значение маски\n",
        "            y[_] = to_categorical(mask, num_classes=self.num_classes)                 # конвертирование маски в категориальный формат\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "oZzeR7i0NwR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.Random(seed).shuffle(input_img_path)\n",
        "random.Random(seed).shuffle(target_img_path)"
      ],
      "metadata": {
        "id": "99lI14JuNyVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trin-val"
      ],
      "metadata": {
        "id": "UXHLW-lPXBkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_img_path = input_img_path[:-val_samples]\n",
        "train_target_img_path = target_img_path[:-val_samples]\n",
        "val_input_img_path = input_img_path[-val_samples:]\n",
        "val_target_img_path = target_img_path[-val_samples:]"
      ],
      "metadata": {
        "id": "V6sJZAvtN-Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = datasetGenerator(batch_size,\n",
        "                             img_size,\n",
        "                             train_input_img_path,\n",
        "                             train_target_img_path,\n",
        "                             num_classes)\n",
        "\n",
        "val_gen = datasetGenerator(batch_size,\n",
        "                           img_size,\n",
        "                           val_input_img_path,\n",
        "                           val_target_img_path,\n",
        "                           num_classes,\n",
        "                           validation = True)"
      ],
      "metadata": {
        "id": "5XQ_JN1MN_la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция для свертки"
      ],
      "metadata": {
        "id": "wDUmsLU0XRfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution_operation(entered_input, filters=64):\n",
        "\n",
        "    conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n",
        "    batch_norm1 = BatchNormalization()(conv1)\n",
        "    acti1 = ReLU()(batch_norm1)\n",
        "\n",
        "\n",
        "    conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(acti1)\n",
        "    batch_norm2 = BatchNormalization()(conv2)\n",
        "    acti2 = ReLU()(batch_norm2)\n",
        "\n",
        "    return acti2"
      ],
      "metadata": {
        "id": "-TnOSDvpOA9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder - Decoder"
      ],
      "metadata": {
        "id": "AiixSPyXXVaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# На входе 2 параметра - предыдущий слой и число фильтров (генерируемых карт признаков)\n",
        "def encoder(entered_input, filters=64):\n",
        "\n",
        "    encod1 = convolution_operation(entered_input, filters)                            # функция свертки - 2 синих блока\n",
        "    MaxPool1 = MaxPooling2D(strides = (2,2))(encod1)                                  # зеленый блок\n",
        "    return encod1, MaxPool1                                                           # функция возвращает латеральное соединение и выход из слоя\n",
        "\n",
        "# На входе 3 параметра - предыдущий слой и латеральное соединение и число фильтров (генерируемых карт признаков)\n",
        "def decoder(entered_input, skip, filters=64):\n",
        "    Upsample = Conv2DTranspose(filters,\n",
        "                               (2, 2),\n",
        "                               strides=2,\n",
        "                               padding=\"same\")(entered_input)                                        # красный блок\n",
        "    Connect_Skip = Concatenate()([Upsample, skip])                                    # белый блок (объединение латерального соединения и выхода предыдущего слоя)\n",
        "    out = convolution_operation(Connect_Skip, filters)                                # функция свертки - 2 синих блока\n",
        "    return out                                                                        # функция возвращает выход из слоя"
      ],
      "metadata": {
        "id": "xD6c-fjxODri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сastom U-net"
      ],
      "metadata": {
        "id": "j3bMjZ29XcPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def U_Net(img_size, num_classes):\n",
        "    # Входной слой - желтый блок\n",
        "    inputs = Input(img_size)\n",
        "\n",
        "    # Блоки кодировщика и латеральные соединения\n",
        "    skip1, encoder_1 = encoder(inputs, 64)\n",
        "    skip2, encoder_2 = encoder(encoder_1, 64*2)\n",
        "    skip3, encoder_3 = encoder(encoder_2, 64*4)\n",
        "    skip4, encoder_4 = encoder(encoder_3, 64*8)\n",
        "\n",
        "    # Бутылочное горлышко\n",
        "    conv_block = convolution_operation(encoder_4, 64*16)\n",
        "\n",
        "    # Блоки декодировщика\n",
        "    decoder_1 = decoder(conv_block, skip4, 64*8)\n",
        "    decoder_2 = decoder(decoder_1, skip3, 64*4)\n",
        "    decoder_3 = decoder(decoder_2, skip2, 64*2)\n",
        "    decoder_4 = decoder(decoder_3, skip1, 64)\n",
        "\n",
        "    # Выходной слой (фиолетовый блок)\n",
        "    outputs = Conv2D(num_classes,\n",
        "                     kernel_size = (1, 1),\n",
        "                     padding=\"same\",\n",
        "                     activation=\"softmax\")(decoder_4)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "QatSHorZOoCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)                                           # размер к которому преобразуется изображение\n",
        "model = U_Net(input_shape, num_classes)                                               # инициализация модели"
      ],
      "metadata": {
        "id": "Y3p166YiU340"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Компиляция модели"
      ],
      "metadata": {
        "id": "eb8Hf5S4Xzm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam' ,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"segmentation.keras\",\n",
        "                                    monitor='val_loss',\n",
        "                                    save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "fM0XLcITVEw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# график структуры модели\n",
        "tf.keras.utils.plot_model(model, \"model.png\",\n",
        "                          show_shapes=True,\n",
        "                          show_dtype=False,\n",
        "                          show_layer_names=True,\n",
        "                          rankdir='TB',\n",
        "                          expand_nested=False,\n",
        "                          dpi=70)"
      ],
      "metadata": {
        "id": "DFi6LAabVGCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение модели"
      ],
      "metadata": {
        "id": "7Fh7Ln0PYET5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_gen,\n",
        "                    validation_data=val_gen,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=callbacks\n",
        "                   )"
      ],
      "metadata": {
        "id": "VKNUUsMIVH0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Графики точности и потерь"
      ],
      "metadata": {
        "id": "j0IZHY6QYIH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']                                                     # данные о точности на обучающей выборке\n",
        "val_acc = history.history['val_accuracy']                                             # данные о точности на проверочной выборке\n",
        "loss = history.history['loss']                                                        # данные об ошибке на обучающей выборке\n",
        "val_loss = history.history['val_loss']                                                # данные об ошибке на проверочной выборке\n",
        "epochs = range(1, len(acc) + 1)                                                       # массив со значениями для оси абсцисс (Х)\n",
        "plt.plot(epochs, acc, 'r', label='Точность на обучающей выборке')                     # график точность на обучающей выборке\n",
        "plt.plot(epochs, val_acc, 'bo', label='Точность на проверочной выборке')              # график точность на проверочной выборке\n",
        "plt.title('График точности на обучающей и проверочной выборках')                      # заголовок графика\n",
        "plt.legend()                                                                          # легенда графика"
      ],
      "metadata": {
        "id": "z0ooJtKaVI64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Потери на обучающей выборке')                      # график потерь (ошибки) на обучающей выборке\n",
        "plt.plot(epochs, val_loss, 'bo', label='Потери на валидационной выборке')             # график потерь на проверочной выборке\n",
        "plt.title('График потерь на обучающей и проверочной выборках')                        # заголовок графика\n",
        "plt.legend()                                                                          # легенда графика\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wd59E97AVe6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация резльутатов"
      ],
      "metadata": {
        "id": "DpyyR7sGYMHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Входное изображение', 'Оригинальная маска', 'Предсказанная маска']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[0])\n",
        "    plt.imshow(display_list[i],alpha=0.8)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DCFjTktoVMlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(10):\n",
        "    img = np.array(load_img(val_input_img_path[index],\n",
        "                            target_size=(256, 256),\n",
        "                            color_mode='rgb'))                                        # картинка для предсказания\n",
        "    mask = np.array(load_img(val_target_img_path[index],\n",
        "                             target_size=(256, 256),\n",
        "                             color_mode='grayscale'))                                 # маска для сравнения с предсказанием\n",
        "\n",
        "    # Запускаем модель в режиме предсказания\n",
        "    test = model.predict(np.expand_dims(img, 0) / 255)\n",
        "\n",
        "    # Выбираем наиболее веротный класс\n",
        "    test = np.argmax(test, axis=-1)\n",
        "\n",
        "    display([img.reshape(1, 256, 256, 3)[0], mask, test[0]])"
      ],
      "metadata": {
        "id": "NeI7C-q2VN_N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}